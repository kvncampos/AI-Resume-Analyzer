{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Resume Analyzer","text":"<p>Welcome to the documentation for the AI Resume Analyzer project! This project aims to analyze resumes against job descriptions using advanced AI techniques. Below, you'll find an overview of the project, what I learned during its development, and the reasoning behind its creation.</p>"},{"location":"#high-level-design","title":"High-Level Design","text":"<p>Here's an overview of the infrastructure:</p> <p></p> <p>AI-Resume Analyzer Design</p>"},{"location":"#overview","title":"Overview","text":"<p>The AI Resume Analyzer is a tool designed to: - Evaluate resumes against job descriptions. - Provide actionable feedback for candidates. - Help recruiters make informed decisions.</p> <p>This project leverages: - Streamlit for the frontend. - Python libraries like <code>langchain</code> and <code>pypdf</code> for AI and PDF processing. - Docker for containerization.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ol> <li>What I Learned</li> <li>Reason for This Project</li> <li>LLM Overview</li> <li>About Me</li> <li>Resources</li> </ol> <p>Click the links above to explore more about this project and its journey!</p>"},{"location":"about/","title":"About Me","text":"<p>Hi! I'm Kevin, a passionate developer and lifelong learner. I specialize in: - Python applications. - Automation and streamlining processes. - Building user-friendly tools to solve complex problems.</p> <p>Feel free to connect with me on: - LinkedIn - GitHub - Visit Porfolio for more information about me.</p> <p>Thank you for visiting this documentation! \ud83d\ude0a</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>Welcome to the AI Resume Analyzer! Follow this guide to prepare your environment and get the application up and running.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites","text":"<p>Before running the containers, make sure the following are completed:</p> <ol> <li>Install Docker and Docker Compose    Ensure that Docker and Docker Compose are installed on your system:</li> <li>Docker Installation Guide</li> <li> <p>Docker Compose Installation Guide</p> </li> <li> <p>Download Required Models    The application relies on Ollama Models, with the default being <code>llama3.2:latest</code>. Follow these steps to download the models:    <pre><code>ollama pull llama3.2:latest\n</code></pre></p> </li> </ol>"},{"location":"getting_started/#steps-to-prepare-and-run","title":"Steps to Prepare and Run","text":""},{"location":"getting_started/#1-download-and-verify-the-model","title":"1. Download and Verify the Model","text":"<pre><code># Command to download the model\nollama pull llama3.2:latest\n</code></pre> <ul> <li>Ensure that the model is downloaded correctly.</li> <li>Verify the installation using:   <pre><code>ollama list\n</code></pre></li> </ul> <p>::: details More Information If you need additional models, visit the Ollama documentation. :::</p>"},{"location":"getting_started/#2-start-the-containers","title":"2. Start the Containers","text":"<p>Use the following commands to build and start the containers:</p> Docker ComposeAlternative Command <pre><code>docker compose up --build\n</code></pre> <pre><code>invoke build\n</code></pre>"},{"location":"getting_started/#3-access-the-application","title":"3. Access the Application","text":"<p>Once the containers are running, you can access the services via the following URLs:</p> <ul> <li>Streamlit App: http://localhost:8501</li> <li>MkDocs Documentation: http://localhost:8000</li> </ul>"},{"location":"getting_started/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues, consider the following:</p> <ul> <li> <p>Model Not Found:</p> <ul> <li>Double-check that <code>llama3.2:latest</code> has been downloaded using <code>ollama pull</code>.</li> <li>Verify that your <code>ollama</code> service is running.</li> </ul> </li> <li> <p>Docker Issues:</p> <ul> <li>Run:   <pre><code>docker system prune -af\n</code></pre></li> <li>Rebuild the containers:   <pre><code>docker compose up --build\n</code></pre></li> </ul> </li> </ul>"},{"location":"getting_started/#resources","title":"Resources","text":"<ul> <li>Ollama Documentation: https://ollama.ai/docs</li> <li>Docker Compose Reference: https://docs.docker.com/compose</li> <li>MkDocs Material: https://squidfunk.github.io/mkdocs-material</li> </ul>"},{"location":"getting_started/#quick-checklist","title":"Quick Checklist","text":"<ul> <li> Docker and Docker Compose installed.</li> <li> <code>ollama pull llama3.2:latest</code> executed successfully.</li> <li> Containers started using <code>docker compose up</code>.</li> </ul>"},{"location":"getting_started/#youre-ready-to-go","title":"\ud83d\ude80 You're Ready to Go!","text":"<p>Enjoy exploring and using the AI Resume Analyzer! If you have questions or feedback, feel free to reach out.</p>"},{"location":"llm_overview/","title":"Understanding the Code","text":"<p>This document explains the key components and functionality of the code that integrates with the Ollama LLM (Large Language Model) for analyzing resumes and job descriptions.</p>"},{"location":"llm_overview/#overview","title":"Overview","text":"<p>The code is structured to:</p> <ol> <li>Load environment variables.</li> <li>Initialize the Ollama LLM with a specified model.</li> <li>Provide utility functions for interacting with the LLM.</li> <li>Analyze job descriptions and resumes to produce insights.</li> </ol>"},{"location":"llm_overview/#key-components","title":"Key Components","text":""},{"location":"llm_overview/#1-loading-environment-variables","title":"1. Loading Environment Variables","text":"<pre><code>from dotenv import load_dotenv\nload_dotenv()\n</code></pre> <p>Purpose: Loads environment variables from a <code>.env</code> file into the application. These variables include the model name for the LLM.</p>"},{"location":"llm_overview/#example","title":"Example:","text":"<pre><code>.env file:\nOLLAMA_MODEL=llama3.2:latest\n</code></pre>"},{"location":"llm_overview/#2-initializing-the-llm","title":"2. Initializing the LLM","text":"<pre><code>LLM_MODEL = os.environ.get(\"OLLAMA_MODEL\", default=\"llama3.2:latest\")\nllm = OllamaLLM(\n    model=LLM_MODEL,\n)\n</code></pre> <ul> <li>LLM_MODEL: Retrieves the model name from the environment variables or uses <code>\"llama3.2:latest\"</code> as the default.- OllamaLLM: Initializes the LLM using the specified model.</li> </ul>"},{"location":"llm_overview/#3-templates-for-prompts","title":"3. Templates for Prompts","text":"<pre><code>from .templates import OLLAMA_TEMPLATES\n</code></pre> <ul> <li>OLLAMA_TEMPLATES: Contains predefined templates for different tasks such as job description validation and resume analysis.Templates define the structure of the input prompts provided to the LLM.</li> </ul>"},{"location":"llm_overview/#4-invoking-the-llm","title":"4. Invoking the LLM","text":"<p><pre><code>def invoke_llm(template_name: str, inputs: dict) -&gt; str:\n</code></pre> This helper function:</p> <ul> <li>Takes a template name and input variables.</li> <li>Validates the template name.</li> <li>Constructs a <code>PromptTemplate</code> using the template and inputs.</li> <li>Executes the chain combining the prompt and the LLM.</li> <li>Returns the response from the LLM.</li> </ul> Example Workflow <p>Input:</p> <pre><code>invoke_llm(\"RESUME_ANALYSIS\", {\"resume\": \"Sample Resume\", \"job_description\": \"Sample Job Description\"})\n</code></pre> <p>Output: The LLM\u2019s analysis of the resume against the job description.</p>"},{"location":"llm_overview/#5-job-description-validation","title":"5. Job Description Validation","text":"<pre><code>def analyze_job_description(job_description: str) -&gt; bool:\n</code></pre> <p>Purpose: Checks if the job description is valid.</p> <p>Process:</p> <ol> <li>Ensures the input is non-empty.</li> <li>Invokes the LLM with the <code>JOB_DESCRIPTION</code> template.</li> <li>Validates that the LLM\u2019s response is either <code>True</code> or <code>False</code>.</li> </ol> <p>Returns: <code>True</code> if the job description is valid, <code>False</code> otherwise.</p>"},{"location":"llm_overview/#example_1","title":"Example:","text":"<ul> <li> <p>Input:</p> <pre><code>analyze_job_description(\"We are looking for a Python developer with Django experience.\")\n</code></pre> </li> <li> <p>Output:</p> <pre><code>True\n</code></pre> </li> </ul>"},{"location":"llm_overview/#6-resume-analysis","title":"6. Resume Analysis","text":"<pre><code>def analyze_resume(full_resume: str, job_description: str) -&gt; str:\n</code></pre> <p>Purpose: Analyzes a resume against a job description.</p> <p>Process:</p> <ol> <li>Ensures both inputs are non-empty.</li> <li>Invokes the LLM with the <code>RESUME_ANALYSIS</code> template.</li> </ol> <p>Returns: A detailed analysis string from the LLM.</p>"},{"location":"llm_overview/#example_2","title":"Example:","text":"<ul> <li> <p>Input:</p> <pre><code>analyze_resume(\n    \"Experienced Python developer with Django expertise.\",\n    \"Looking for a Python developer with Django and Flask experience.\"\n)\n</code></pre> </li> <li> <p>Output:</p> <pre><code>A string containing the LLM\u2019s analysis of the resume compared to the job description.\n</code></pre> </li> </ul>"},{"location":"llm_overview/#error-handling","title":"Error Handling","text":""},{"location":"llm_overview/#invalid-template-name","title":"Invalid Template Name:","text":"<pre><code>if template_name not in OLLAMA_TEMPLATES:\n    raise ValueError(f\"Invalid template name: {template_name}\")\n</code></pre> <p>Ensures only valid templates are used.</p>"},{"location":"llm_overview/#empty-input-validation","title":"Empty Input Validation:","text":"<ul> <li><code>analyze_job_description</code>: Ensures the job description is non-empty.</li> <li><code>analyze_resume</code>: Ensures both resume and job description inputs are non-empty.</li> </ul>"},{"location":"llm_overview/#unexpected-responses","title":"Unexpected Responses:","text":"<pre><code>if response not in [\"True\", \"False\"]:\n    raise RuntimeError(f\"Unexpected response from LLM: {response}\")\n</code></pre> <p>Ensures the LLM\u2019s response is predictable.</p>"},{"location":"llm_overview/#summary","title":"Summary","text":"<p>This code provides a robust framework for leveraging the Ollama LLM to:</p> <ol> <li>Validate job descriptions.</li> <li>Analyze resumes against job descriptions.</li> <li>Return structured and actionable insights.</li> </ol> <p>The use of templates ensures consistency in prompts, while helper functions like <code>invoke_llm</code> simplify interaction with the LLM. Error handling and input validation ensure reliability and robustness.</p>"},{"location":"reason-for-project/","title":"Reason for This Project","text":"<p>The AI Resume Analyzer project was born out of a desire to solve real-world problems. Here's why I created this:</p>"},{"location":"reason-for-project/#1-personal-motivation","title":"1. Personal Motivation","text":"<p>As someone passionate about technology, I wanted to build a tool that: - Helps job seekers refine their resumes. - Assists recruiters in evaluating candidates more efficiently.</p>"},{"location":"reason-for-project/#2-gaps-in-existing-tools","title":"2. Gaps in Existing Tools","text":"<p>Many resume analyzers exist, but few: - Provide actionable feedback. - Are accessible to everyone.</p>"},{"location":"reason-for-project/#3-skill-development","title":"3. Skill Development","text":"<p>This project was also an opportunity to: - Improve my skills in Python, Docker, and AI. - Learn and use new libraries like <code>langchain</code>.</p>"},{"location":"reason-for-project/#long-term-vision","title":"Long-Term Vision","text":"<p>The goal is to make this tool robust enough to be used in professional recruitment processes. Features like resume scoring, keyword suggestions, and detailed analysis are in the pipeline.</p>"},{"location":"resources/","title":"Resources and Credits","text":"<p>This project was made possible by leveraging the knowledge, tools, and inspiration from the following resources:</p>"},{"location":"resources/#1-prompting-with-llama","title":"1. Prompting with Llama","text":"<ul> <li>Source: Llama Documentation - How-to Guides: Prompting</li> <li>Description: This guide provided foundational knowledge on crafting effective prompts for AI models.</li> </ul>"},{"location":"resources/#2-uv-integration-with-docker","title":"2. UV Integration with Docker","text":"<ul> <li>Source: Astral Documentation - UV Docker Integration</li> <li>Description: Helped with setting up UV for managing Python dependencies within a Dockerized environment.</li> </ul>"},{"location":"resources/#3-building-an-end-to-end-rag-application","title":"3. Building an End-to-End RAG Application","text":"<ul> <li>Source: Medium Article - Building an End-to-End RAG Application Using LangChain</li> <li>Description: Inspired the architecture and development of a Resume Analysis Tool using LangChain.</li> </ul>"},{"location":"resources/#thank-you","title":"Thank You!","text":"<p>Special thanks to the creators and maintainers of these resources for their invaluable contributions to the AI and developer communities. Without these resources, this project would not have been possible.</p>"},{"location":"what-i-learned/","title":"What I Learned","text":"<p>This project provided me with invaluable insights and opportunities to grow. Here's a summary of what I learned:</p>"},{"location":"what-i-learned/#1-streamlit-for-interactive-dashboards","title":"1. Streamlit for Interactive Dashboards","text":"<ul> <li>Learned how to create interactive web applications with minimal effort.</li> <li>Explored advanced features like custom themes and session states.</li> </ul>"},{"location":"what-i-learned/#2-ai-powered-resume-analysis","title":"2. AI-Powered Resume Analysis","text":"<ul> <li>Gained experience with <code>langchain</code> for AI-powered text analysis.</li> <li>Integrated AI models to compare resumes with job descriptions.</li> </ul>"},{"location":"what-i-learned/#3-docker-and-deployment","title":"3. Docker and Deployment","text":"<ul> <li>Learned how to containerize the application for portability and ease of deployment.</li> <li>Used Docker Compose to manage multi-service setups.</li> </ul>"},{"location":"what-i-learned/#4-python-libraries","title":"4. Python Libraries","text":"<ul> <li>Mastered libraries like <code>pypdf</code> for PDF parsing and <code>python-dotenv</code> for configuration management.</li> </ul>"},{"location":"what-i-learned/#next-steps","title":"Next Steps","text":"<ul> <li>Dive deeper into machine learning for resume scoring.</li> <li>Optimize the app for large-scale usage.</li> </ul>"}]}